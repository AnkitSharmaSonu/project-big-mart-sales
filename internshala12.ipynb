{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
       "0         0  22.0   7.2500         0         0         1           0   \n",
       "1         1  38.0  71.2833         1         0         0           1   \n",
       "2         1  26.0   7.9250         0         0         1           1   \n",
       "3         1  35.0  53.1000         1         0         0           1   \n",
       "4         0  35.0   8.0500         0         0         1           0   \n",
       "\n",
       "   Sex_male  SibSp_0  SibSp_1     ...      Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       "0         1        0        1     ...            1        0        0        0   \n",
       "1         0        0        1     ...            1        0        0        0   \n",
       "2         0        1        0     ...            1        0        0        0   \n",
       "3         0        0        1     ...            1        0        0        0   \n",
       "4         1        1        0     ...            1        0        0        0   \n",
       "\n",
       "   Parch_4  Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0        0           0           0           1  \n",
       "1        0        0        0           1           0           0  \n",
       "2        0        0        0           0           0           1  \n",
       "3        0        0        0           0           0           1  \n",
       "4        0        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Survived'],axis=1)\n",
    "y=df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda setup\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as tt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale=MinMaxScaler()\n",
    "x_scaled=scale.fit_transform(x)\n",
    "x=pd.DataFrame(x_scaled,columns=x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y=tt(x,y,random_state=56)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as Logreg\n",
    "from sklearn.metrics import f1_score as ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda setup\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll=Logreg()\n",
    "ll.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7763157894736841"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict=ll.predict(train_x)\n",
    "k=ff(train_predict,train_y)\n",
    "test_predict=ll.predict(test_x)\n",
    "k1=ff(test_predict,test_y)\n",
    "k\n",
    "k1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict=ll.predict_proba(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49621428, 0.09587164, 0.12577412, 0.81802542, 0.57560738,\n",
       "       0.11106846, 0.82341898, 0.76070851, 0.56403467, 0.07769335,\n",
       "       0.10428491, 0.09043879, 0.11579757, 0.09786646, 0.64185094,\n",
       "       0.08980572, 0.33781063, 0.11339529, 0.08062363, 0.30121731,\n",
       "       0.09791537, 0.21563194, 0.10612877, 0.57782713, 0.09378536,\n",
       "       0.51864435, 0.09038671, 0.55413887, 0.59681759, 0.11832195,\n",
       "       0.82692543, 0.09045123, 0.47965665, 0.13185273, 0.0214056 ,\n",
       "       0.65895697, 0.21746507, 0.13910794, 0.0707497 , 0.2601947 ,\n",
       "       0.85377311, 0.39614533, 0.26236587, 0.69407649, 0.5114025 ,\n",
       "       0.92722923, 0.3006304 , 0.31103856, 0.1683429 , 0.87807585,\n",
       "       0.1208591 , 0.59849914, 0.23291124, 0.60137879, 0.36782703,\n",
       "       0.60864839, 0.76452867, 0.2647543 , 0.1064338 , 0.37244351,\n",
       "       0.56534895, 0.2647543 , 0.13826138, 0.43601831, 0.13367269,\n",
       "       0.96067884, 0.11120126, 0.09043879, 0.86435851, 0.66853105,\n",
       "       0.92184262, 0.73181028, 0.88762006, 0.43315065, 0.81564493,\n",
       "       0.23519682, 0.86677522, 0.53625501, 0.55341791, 0.11832195,\n",
       "       0.5244852 , 0.11816474, 0.12859435, 0.03383347, 0.71054072,\n",
       "       0.92654592, 0.69567936, 0.10020918, 0.25568632, 0.92765273,\n",
       "       0.30304465, 0.13185506, 0.10303421, 0.13185506, 0.26236587,\n",
       "       0.89997685, 0.3628817 , 0.11579966, 0.55389758, 0.55395444,\n",
       "       0.13185506, 0.11582519, 0.09994414, 0.13995915, 0.13918625,\n",
       "       0.06629115, 0.27883554, 0.05679335, 0.74313946, 0.33596303,\n",
       "       0.23291124, 0.43314003, 0.13910744, 0.1319346 , 0.53616355,\n",
       "       0.33356026, 0.14946059, 0.92458656, 0.10878272, 0.16011538,\n",
       "       0.50686823, 0.49460647, 0.20246832, 0.40179342, 0.9282903 ,\n",
       "       0.28830494, 0.39084308, 0.60134842, 0.13185226, 0.64392351,\n",
       "       0.08990281, 0.09787981, 0.39616879, 0.89733503, 0.13910744,\n",
       "       0.02921998, 0.51323182, 0.07506115, 0.31126781, 0.89792306,\n",
       "       0.93946007, 0.12838695, 0.66691007, 0.10975949, 0.32366885,\n",
       "       0.24256208, 0.10650571, 0.92439873, 0.87654723, 0.8890853 ,\n",
       "       0.51862701, 0.48919439, 0.62762501, 0.0806909 , 0.44900753,\n",
       "       0.09045628, 0.43219975, 0.26062258, 0.12537634, 0.76519009,\n",
       "       0.33093768, 0.25568632, 0.34453508, 0.6379531 , 0.06068838,\n",
       "       0.30438697, 0.11340762, 0.83922693, 0.28598578, 0.91107216,\n",
       "       0.06485546, 0.75202826, 0.58081726, 0.2573454 , 0.2880032 ,\n",
       "       0.44702295, 0.52210637, 0.39921156, 0.06823037, 0.09378189,\n",
       "       0.08794017, 0.24202195, 0.06240027, 0.10955047, 0.91025317,\n",
       "       0.37903099, 0.91229819, 0.26270298, 0.24682465, 0.16050954,\n",
       "       0.15132412, 0.07157518, 0.5736501 , 0.34176612, 0.11579506,\n",
       "       0.1979572 , 0.2647543 , 0.88131902, 0.6113765 , 0.24920241,\n",
       "       0.47028999, 0.4101544 , 0.60134842, 0.10877084, 0.26805874,\n",
       "       0.87444676, 0.60633477, 0.08891122, 0.75697399, 0.13185506,\n",
       "       0.65198665, 0.60134842, 0.13910794, 0.14504822, 0.93615055,\n",
       "       0.09043879, 0.08245551, 0.88840652, 0.55191142, 0.15608008,\n",
       "       0.11343474, 0.33879398, 0.09045123, 0.90453406, 0.22188341,\n",
       "       0.15835414, 0.09043879, 0.72474722, 0.49296537, 0.13375151,\n",
       "       0.76675261, 0.43833486, 0.09097299, 0.30438697, 0.16878502,\n",
       "       0.72034564, 0.39694053, 0.88284576, 0.10870668, 0.03890314,\n",
       "       0.23772726, 0.09664548, 0.21746507, 0.12073757, 0.67310676,\n",
       "       0.09786646, 0.65312797, 0.23291124, 0.5306186 , 0.11126145,\n",
       "       0.90706   , 0.10535767, 0.65504734, 0.79614599, 0.95792817,\n",
       "       0.14235516, 0.44282308, 0.12088862, 0.09043879, 0.43303025,\n",
       "       0.05806836, 0.56441755, 0.09193244, 0.13826089, 0.92820284,\n",
       "       0.28526652, 0.55629536, 0.08609042, 0.09045123, 0.09042905,\n",
       "       0.73970031, 0.13186395, 0.82238616, 0.68717101, 0.49527961,\n",
       "       0.31548268, 0.40080975, 0.06674805, 0.29647312, 0.33752511,\n",
       "       0.07553351, 0.11106846, 0.60134449, 0.09181516, 0.10521722,\n",
       "       0.43204934, 0.0621105 , 0.83137955, 0.09579799, 0.79486214,\n",
       "       0.92301561, 0.54273823, 0.93498026, 0.09572828, 0.04533907,\n",
       "       0.94145466, 0.06924357, 0.34676625, 0.68934827, 0.10875658,\n",
       "       0.54508989, 0.47518799, 0.23392439, 0.11082704, 0.1158503 ,\n",
       "       0.05674106, 0.07924777, 0.31636523, 0.09378536, 0.80394545,\n",
       "       0.60134842, 0.43044414, 0.09989122, 0.23291124, 0.09102166,\n",
       "       0.13910744, 0.10875855, 0.19809045, 0.11108742, 0.54206477,\n",
       "       0.30074078, 0.15691149, 0.78901469, 0.93695813, 0.49012658,\n",
       "       0.34676625, 0.61609805, 0.0904109 , 0.14252501, 0.2336593 ,\n",
       "       0.11341953, 0.13185506, 0.0214056 , 0.25759149, 0.09043879,\n",
       "       0.17683677, 0.09443678, 0.22929628, 0.63758376, 0.06629874,\n",
       "       0.26427731, 0.91715671, 0.08436495, 0.07892129, 0.35328387,\n",
       "       0.4544131 , 0.61936674, 0.05870508, 0.20012348, 0.57550118,\n",
       "       0.40779404, 0.14117099, 0.76551152, 0.32598041, 0.44421253,\n",
       "       0.82744573, 0.06197204, 0.17876928, 0.12326342, 0.24288031,\n",
       "       0.89445625, 0.56451572, 0.11832195, 0.26766293, 0.51582059,\n",
       "       0.79574225, 0.17847369, 0.09045123, 0.74654717, 0.95101704,\n",
       "       0.77572645, 0.9263406 , 0.20914931, 0.65312797, 0.25853035,\n",
       "       0.42075078, 0.48888726, 0.03879348, 0.75353668, 0.88667886,\n",
       "       0.12093636, 0.73356579, 0.44204659, 0.13185506, 0.16108981,\n",
       "       0.92111657, 0.23291124, 0.27954595, 0.39520689, 0.5485971 ,\n",
       "       0.4697808 , 0.37884781, 0.85337737, 0.09039175, 0.09045123,\n",
       "       0.79574225, 0.57927732, 0.05977555, 0.10878272, 0.54788133,\n",
       "       0.74120557, 0.7676363 , 0.91636288, 0.5132471 , 0.13928224,\n",
       "       0.11846266, 0.36977728, 0.08582918, 0.88357108, 0.45030185,\n",
       "       0.11442306, 0.55341791, 0.242472  , 0.11099062, 0.06924989,\n",
       "       0.43785202, 0.94575538, 0.9105423 , 0.57744566, 0.85661297,\n",
       "       0.44969071, 0.65383068, 0.70611978, 0.29630541, 0.83078291,\n",
       "       0.18710453, 0.9248858 , 0.1042811 , 0.08998625, 0.07894981,\n",
       "       0.55802536, 0.88422171, 0.09346873, 0.07396387, 0.4419461 ,\n",
       "       0.60134842, 0.32048901, 0.22225951, 0.58507027, 0.22516033,\n",
       "       0.20316773, 0.08608077, 0.7006891 , 0.28349614, 0.64438851,\n",
       "       0.71525078, 0.90055656, 0.7992007 , 0.93143428, 0.78768588,\n",
       "       0.50771488, 0.15388125, 0.09043879, 0.09097299, 0.18959896,\n",
       "       0.54194305, 0.13185319, 0.09501184, 0.21760272, 0.44674867,\n",
       "       0.0806909 , 0.08234026, 0.89783382, 0.89671832, 0.95428384,\n",
       "       0.21307203, 0.16512484, 0.62797577, 0.25759149, 0.73234982,\n",
       "       0.78825736, 0.69069861, 0.90566477, 0.93019604, 0.09045123,\n",
       "       0.50174608, 0.77743575, 0.22972984, 0.17847369, 0.60143952,\n",
       "       0.56528167, 0.60069866, 0.08990281, 0.22979606, 0.87993464,\n",
       "       0.13370707, 0.4258216 , 0.35597829, 0.68124747, 0.09362054,\n",
       "       0.10647072, 0.162278  , 0.7039877 , 0.75284763, 0.41981522,\n",
       "       0.89455805, 0.58266579, 0.21752875, 0.08608077, 0.08608077,\n",
       "       0.08607531, 0.43219975, 0.09351598, 0.86758326, 0.08795197,\n",
       "       0.07559146, 0.85556386, 0.2302965 , 0.05677759, 0.11344542,\n",
       "       0.55366914, 0.13185506, 0.92900882, 0.32664081, 0.30438697,\n",
       "       0.12073757, 0.10644546, 0.10880073, 0.11264321, 0.25568632,\n",
       "       0.43713025, 0.74285688, 0.0214056 , 0.4633221 , 0.94183584,\n",
       "       0.29755378, 0.12198547, 0.88120634, 0.50854913, 0.2569687 ,\n",
       "       0.4081143 , 0.73096677, 0.11364408, 0.05401916, 0.0214056 ,\n",
       "       0.09043879, 0.58511782, 0.10927697, 0.09179267, 0.0620274 ,\n",
       "       0.91906667, 0.07838856, 0.527043  , 0.90038787, 0.38583399,\n",
       "       0.45213513, 0.70377364, 0.54257291, 0.097856  , 0.09038671,\n",
       "       0.09042905, 0.09043879, 0.20955514, 0.60134548, 0.13910794,\n",
       "       0.61609903, 0.12434915, 0.09443678, 0.1066415 , 0.64294668,\n",
       "       0.90207985, 0.43435502, 0.28299839, 0.17847369, 0.86999434,\n",
       "       0.28079451, 0.48512174, 0.6855146 , 0.910341  , 0.74148212,\n",
       "       0.04195829, 0.60136704, 0.04859618, 0.60134842, 0.15935604,\n",
       "       0.43620676, 0.09056829, 0.15712596, 0.18934025, 0.76923013,\n",
       "       0.08611453, 0.10884097, 0.93033137, 0.22786145, 0.21746507,\n",
       "       0.06931392, 0.85487745, 0.03624275, 0.38340007, 0.38985114,\n",
       "       0.67562993, 0.85639664, 0.09038671, 0.43206739, 0.75086531,\n",
       "       0.89293482, 0.09758662, 0.05137506, 0.05893083, 0.04219931,\n",
       "       0.60134842, 0.13910794, 0.72474722, 0.06629874, 0.83525803,\n",
       "       0.67904353, 0.10202911, 0.04891539, 0.13021451, 0.27158431,\n",
       "       0.40186755, 0.12602439, 0.58836118, 0.13943784, 0.95644733,\n",
       "       0.78492763, 0.04058877, 0.16655236, 0.13272753, 0.65312797,\n",
       "       0.0898575 , 0.60132001, 0.23012321, 0.13185506, 0.50690762,\n",
       "       0.8677624 , 0.17375155, 0.92863925, 0.80149733, 0.2569687 ,\n",
       "       0.17012447, 0.07481958, 0.13910794, 0.102119  , 0.06777181,\n",
       "       0.09687508, 0.24682465, 0.64930569, 0.56584694, 0.67562634,\n",
       "       0.10650571, 0.13185366, 0.09043879, 0.92394714, 0.2880032 ,\n",
       "       0.10660881, 0.79514979, 0.94194531, 0.39647215, 0.68062255,\n",
       "       0.58111479, 0.13404307, 0.93615055, 0.92876618, 0.70555981,\n",
       "       0.11122792, 0.94109135, 0.68082996, 0.09045123, 0.24725843,\n",
       "       0.66500324, 0.37096632, 0.49677852, 0.23392439, 0.61148364,\n",
       "       0.76064602, 0.64598593, 0.94770187])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr=train_predict[:,1]\n",
    "tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tr)):\n",
    "    if tr[i]>0.5:\n",
    "        tr[i]=1\n",
    "    else:\n",
    "        tr[i]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7480314960629921"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "k=ff(tr,train_y)\n",
    "k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
